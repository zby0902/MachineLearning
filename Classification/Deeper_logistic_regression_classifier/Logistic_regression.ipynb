{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "- Implement the link function for logistic regression.\n",
    "- Write a function to compute the derivative of the log likelihood function with respect to a single coefficient.\n",
    "- Implement gradient ascent.\n",
    "- Compute classification accuracy for the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphlab import SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to bzha0010@student.monsh.edu and will expire on June 12, 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\zby0902\\AppData\\Local\\Temp\\graphlab_server_1531817637.log.0\n"
     ]
    }
   ],
   "source": [
    "products = SFrame('./amazon_baby_subset.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">All of my kids have cried<br>non-stop when I tried to ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature's Lullabies Second<br>Year Sticker Calendar ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">We wanted to get<br>something to keep track ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature's Lullabies Second<br>Year Sticker Calendar ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">My daughter had her 1st<br>baby over a year ago. ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Lamaze Peekaboo, I Love<br>You ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One of baby's first and<br>favorite books, and i ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">SoftPlay Peek-A-Boo<br>Where's Elmo A Childr ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Very cute interactive<br>book! My son loves this ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[5 rows x 4 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\treview\tstr\n",
       "\trating\tfloat\n",
       "\tsentiment\tint\n",
       "\n",
       "Rows: 5\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "|              name             |             review            | rating | sentiment |\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "| Stop Pacifier Sucking with... | All of my kids have cried ... |  5.0   |     1     |\n",
       "| Nature's Lullabies Second ... | We wanted to get something... |  5.0   |     1     |\n",
       "| Nature's Lullabies Second ... | My daughter had her 1st ba... |  5.0   |     1     |\n",
       "|  Lamaze Peekaboo, I Love You  | One of baby's first and fa... |  4.0   |     1     |\n",
       "| SoftPlay Peek-A-Boo Where'... | Very cute interactive book... |  5.0   |     1     |\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26579, 26493)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of positive and negative sentiment\n",
    "products[products['sentiment'] == 1].shape[0], products.shape[0] - products[products['sentiment'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('important_words.json','r') as f:\n",
    "    important_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products.fillna('review','');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating the word_counts of all important words we need to tranform all reviews to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Should unify the upper and lower case to avoid missed count\n",
    "#products['review_clean'] = products['review_clean'].apply(lambda s: s.lower() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate the count for each importan word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s: s.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Quiz:`` No of reviews contains 'perfect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955L"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(products['perfect'] != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(df,features,label):\n",
    "    \"\"\"\n",
    "    Extract the feature matrix and the target matrix from the dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: The dataframe(SFrame or Dataframe) containing the data points\n",
    "    \n",
    "    features: list of features picked to form the feature matrix\n",
    "    \n",
    "    label: The target feature of the model\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    feature_matrix : A 2D array containing all features for all data points\n",
    "    \n",
    "    class_matrix : A 1D array containing the class labels for all instances\n",
    "    \"\"\"\n",
    "    df['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    feature_matrix = df[features].to_numpy()\n",
    "    class_matrix = df[label].to_numpy()\n",
    "        \n",
    "    return feature_matrix, class_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_feature_matrix(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_probability(feature_matrix, weights):\n",
    "    \"\"\"\n",
    "    Predict the probabilitie of each instances as class 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: The 2D array containing all selected features of all data points\n",
    "    \n",
    "    weights: The learnt coefficients of the linear score function\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    prob: The probility of all instances as class 1\n",
    "    \"\"\"\n",
    "    scores = np.dot(feature_matrix,weights)\n",
    "    prob = 1 / (1+np.exp(-scores))\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: A test of the previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The derivative for single feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    \"\"\"\n",
    "    compute the derivative of the log-likelihood with respect to a single feature\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    errors: A 1D array containing differences between the boolean of the instance as 1 and its probility to be 1\n",
    "    \n",
    "    feature: A 1D array containing values of a single feature for all data points\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The derivative of the log-likelihood, which is the derivative with respect to a single coefficient w_j. \n",
    "    \"\"\"\n",
    "    return np.dot(errors,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log-likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix,sentiment,weights):\n",
    "    \"\"\"\n",
    "    compute the log-likelihood of all features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: A 2D array containing all selected featuers of all instances\n",
    "    \n",
    "    sentiment: A 1D array containing class lables of all instances\n",
    "    \n",
    "    weights: The coefficients of all features\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    log_like : The log likelihood for the current iteration\n",
    "    \"\"\"\n",
    "    indicator = sentiment == 1\n",
    "    scores = np.dot(feature_matrix,weights)\n",
    "    log_like = np.sum((indicator-1)*scores - np.log(1.+np.exp(-scores)))\n",
    "    \n",
    "    return log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the derivative related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.33141161544\n",
      "output of compute_log_likelihood = -5.33141161544\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ -1==+1,1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])),np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll = sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_log_likelihood           =', correct_ll\n",
    "print 'output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_sentiment, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix, sentiment, \n",
    "                        initial_coefficients, step_size, max_iter):\n",
    "    \"\"\"\n",
    "    learn the optimal weights for the logistic regression model using gradiend ascent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: A 2D array of features for all instances\n",
    "    \n",
    "    sentimnet: A 1D array of true class labels\n",
    "    \n",
    "    initial_coefficients: The initial weights for all features\n",
    "    \n",
    "    step_size: The step_size for gradient ascent\n",
    "    \n",
    "    max_iter: The limit number of iterations\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The final coefficents for all features(a 1D array)\n",
    "    \"\"\"\n",
    "    weights = np.array(initial_coefficients)\n",
    "    \n",
    "    for itr in range(max_iter):\n",
    "        prediction = predict_probability(feature_matrix, weights)\n",
    "        indicator = sentiment == 1\n",
    "        errors = indicator - prediction\n",
    "        \n",
    "        for j in range(len(weights)):\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "            weights[j] += step_size * derivative\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, weights)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)      \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model to learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （Own test of tune step_size）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -32421.40457758\n",
      "iteration   1: log likelihood of observed labels = -32361.44206679\n",
      "iteration   2: log likelihood of observed labels = -46284.52561600\n",
      "iteration   3: log likelihood of observed labels = -76428.62370127\n",
      "iteration   4: log likelihood of observed labels = -78302.76681108\n",
      "iteration   5: log likelihood of observed labels = -61756.91248927\n",
      "iteration   6: log likelihood of observed labels = -65412.29017649\n",
      "iteration   7: log likelihood of observed labels = -52088.67904541\n",
      "iteration   8: log likelihood of observed labels = -52970.08854271\n",
      "iteration   9: log likelihood of observed labels = -45218.93727170\n",
      "iteration  10: log likelihood of observed labels = -45361.30108853\n",
      "iteration  11: log likelihood of observed labels = -40648.70439891\n",
      "iteration  12: log likelihood of observed labels = -40837.87419519\n",
      "iteration  13: log likelihood of observed labels = -37737.60805148\n",
      "iteration  14: log likelihood of observed labels = -38096.90198600\n",
      "iteration  15: log likelihood of observed labels = -35906.94136238\n",
      "iteration  20: log likelihood of observed labels = -34437.86699966\n",
      "iteration  30: log likelihood of observed labels = -31928.21901705\n",
      "iteration  40: log likelihood of observed labels = -30516.62613927\n",
      "iteration  50: log likelihood of observed labels = -29708.39576794\n",
      "iteration  60: log likelihood of observed labels = -29163.86050039\n",
      "iteration  70: log likelihood of observed labels = -28772.49401500\n",
      "iteration  80: log likelihood of observed labels = -28483.95038254\n",
      "iteration  90: log likelihood of observed labels = -28264.32050244\n",
      "iteration 100: log likelihood of observed labels = -28092.99062902\n",
      "iteration 200: log likelihood of observed labels = -27423.08864568\n",
      "iteration 300: log likelihood of observed labels = -27267.80813732\n"
     ]
    }
   ],
   "source": [
    "coefficients3 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-4, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36222.96935992\n",
      "iteration   1: log likelihood of observed labels = -35712.39105128\n",
      "iteration   2: log likelihood of observed labels = -35244.87859896\n",
      "iteration   3: log likelihood of observed labels = -34814.71047654\n",
      "iteration   4: log likelihood of observed labels = -34417.49249984\n",
      "iteration   5: log likelihood of observed labels = -34049.53704724\n",
      "iteration   6: log likelihood of observed labels = -33707.68013590\n",
      "iteration   7: log likelihood of observed labels = -33389.18706537\n",
      "iteration   8: log likelihood of observed labels = -33091.68390021\n",
      "iteration   9: log likelihood of observed labels = -32813.10213697\n",
      "iteration  10: log likelihood of observed labels = -32551.63288262\n",
      "iteration  11: log likelihood of observed labels = -32305.68866325\n",
      "iteration  12: log likelihood of observed labels = -32073.87149461\n",
      "iteration  13: log likelihood of observed labels = -31854.94611400\n",
      "iteration  14: log likelihood of observed labels = -31647.81747208\n",
      "iteration  15: log likelihood of observed labels = -31451.51174681\n",
      "iteration  20: log likelihood of observed labels = -30604.89435663\n",
      "iteration  30: log likelihood of observed labels = -29377.47809516\n",
      "iteration  40: log likelihood of observed labels = -28521.99752669\n",
      "iteration  50: log likelihood of observed labels = -27886.49484229\n",
      "iteration  60: log likelihood of observed labels = -27393.23784609\n",
      "iteration  70: log likelihood of observed labels = -26997.93220005\n",
      "iteration  80: log likelihood of observed labels = -26673.29313129\n",
      "iteration  90: log likelihood of observed labels = -26401.50080625\n",
      "iteration 100: log likelihood of observed labels = -26170.37538181\n",
      "iteration 200: log likelihood of observed labels = -24942.39926418\n",
      "iteration 300: log likelihood of observed labels = -24453.88975921\n"
     ]
    }
   ],
   "source": [
    "## own experiment on step_size\n",
    "coefficients2 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-5, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -33086.51747495\n",
      "iteration   1: log likelihood of observed labels = -31881.46236863\n",
      "iteration   2: log likelihood of observed labels = -34970.52252035\n",
      "iteration   3: log likelihood of observed labels = -46563.94189047\n",
      "iteration   4: log likelihood of observed labels = -58698.17681138\n",
      "iteration   5: log likelihood of observed labels = -50519.96779930\n",
      "iteration   6: log likelihood of observed labels = -51655.45860328\n",
      "iteration   7: log likelihood of observed labels = -43137.69324957\n",
      "iteration   8: log likelihood of observed labels = -43025.34336656\n",
      "iteration   9: log likelihood of observed labels = -37996.53459829\n",
      "iteration  10: log likelihood of observed labels = -37510.65043503\n",
      "iteration  11: log likelihood of observed labels = -34495.37279778\n",
      "iteration  12: log likelihood of observed labels = -34073.63979852\n",
      "iteration  13: log likelihood of observed labels = -32174.27038303\n",
      "iteration  14: log likelihood of observed labels = -31878.28231782\n",
      "iteration  15: log likelihood of observed labels = -30619.30508562\n",
      "iteration  20: log likelihood of observed labels = -28628.41342589\n",
      "iteration  30: log likelihood of observed labels = -26528.62819264\n",
      "iteration  40: log likelihood of observed labels = -25540.14817149\n",
      "iteration  50: log likelihood of observed labels = -24943.30584536\n",
      "iteration  60: log likelihood of observed labels = -24542.12426954\n",
      "iteration  70: log likelihood of observed labels = -24268.09308719\n",
      "iteration  80: log likelihood of observed labels = -24083.99296556\n",
      "iteration  90: log likelihood of observed labels = -23961.93411093\n",
      "iteration 100: log likelihood of observed labels = -23882.01325238\n",
      "iteration 200: log likelihood of observed labels = -23727.66293400\n",
      "iteration 300: log likelihood of observed labels = -23712.30643237\n"
     ]
    }
   ],
   "source": [
    "coefficients4 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=8e-5, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['predic_prob1'] = predict_probability(feature_matrix,coefficients)\n",
    "products['predic_prob2'] = predict_probability(feature_matrix,coefficients2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict sentiment using the learnt coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix,coefficients)\n",
    "scores2 = np.dot(feature_matrix,coefficients2)\n",
    "scores4 = np.dot(feature_matrix,coefficients4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['predic_scores1'] = scores\n",
    "products['predic_scores2'] = scores2\n",
    "products['predic_scores4'] = scores4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['predic_sentiment1'] = products['predic_scores1'].apply(lambda s: 1 if s>0 else -1)\n",
    "products['predic_sentiment2'] = products['predic_scores2'].apply(lambda s: 1 if s>0 else -1)\n",
    "products['predic_sentiment4'] = products['predic_scores4'].apply(lambda s: 1 if s>0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25126L, 25679L)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of positive_predicted instances\n",
    "(products['predic_sentiment1'] == 1).sum(),(products['predic_sentiment2'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.7877)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of coefficients and coefficients2\n",
    "round((products['predic_sentiment1'] == products['sentiment']).sum()*1./products.shape[0],2),round((products['predic_sentiment2'] == products['sentiment']).sum()*1./products.shape[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of coefficients4 which is believed to be opitimum regarding the step_size\n",
    "round((products['predic_sentiment4'] == products['sentiment']).sum()*1./products.shape[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients)[1:]\n",
    "word_coefficient_paris = [(word,coef) for word,coef in zip(important_words,coefficients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_coef_dict = {a:b for a,b in zip(important_words,coefficients)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.033069515294752737"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coef_dict['work']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ten most positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.066546084170457695),\n",
       " ('love', 0.065890762922123258),\n",
       " ('easy', 0.06479458680257838),\n",
       " ('little', 0.045435626308421372),\n",
       " ('loves', 0.044976401394906038),\n",
       " ('well', 0.030135001092107074),\n",
       " ('perfect', 0.029739937104968462),\n",
       " ('old', 0.020077541034775381),\n",
       " ('nice', 0.018408707995268992),\n",
       " ('daughter', 0.01770319990570169)]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_coefficient_paris,key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ten most negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', -0.053860148445203121),\n",
       " ('product', -0.041511033392108897),\n",
       " ('money', -0.038982037286487109),\n",
       " ('work', -0.033069515294752737),\n",
       " ('even', -0.030051249236035808),\n",
       " ('disappointed', -0.028978976142317068),\n",
       " ('get', -0.028711552980192581),\n",
       " ('back', -0.027742697230661331),\n",
       " ('return', -0.026592778462247283),\n",
       " ('monitor', -0.024482100545891717)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_coefficient_paris,key=lambda x: x[1])[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
