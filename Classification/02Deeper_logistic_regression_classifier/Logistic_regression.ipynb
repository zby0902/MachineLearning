{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "- Implement the link function for logistic regression.\n",
    "- Write a function to compute the derivative of the log likelihood function with respect to a single coefficient.\n",
    "- Implement gradient ascent.\n",
    "- Compute classification accuracy for the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sframe import  SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] sframe.cython.cy_server: SFrame v2.1 started. Logging C:\\Users\\zby0902\\AppData\\Local\\Temp\\sframe_server_1532162436.log.0\n"
     ]
    }
   ],
   "source": [
    "products = SFrame('amazon_baby_subset.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products= pd.DataFrame(products.to_numpy(),columns=['name','review','rating','sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review rating sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...      5         1  \n",
       "1  We wanted to get something to keep track of ou...      5         1  \n",
       "2  My daughter had her 1st baby over a year ago. ...      5         1  \n",
       "3  One of baby's first and favorite books, and it...      4         1  \n",
       "4  Very cute interactive book! My son loves this ...      5         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26579, 26493)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of positive and negative sentiment\n",
    "products[products['sentiment'] == 1].shape[0], products.shape[0] - products[products['sentiment'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('important_words.json','r') as f:\n",
    "    important_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products.review.fillna('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating the word_counts of all important words we need to tranform all reviews to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Should unify the upper and lower case to avoid missed count\n",
    "#products['review_clean'] = products['review_clean'].apply(lambda s: s.lower() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate the count for each importan word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products.review_clean.str.count(word)# the count will ignore the cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Quiz:`` No of reviews contains 'perfect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4246"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(products['perfect'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(df,features,label):\n",
    "    \"\"\"\n",
    "    Extract the feature matrix and the target matrix from the dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: The dataframe(SFrame or Dataframe) containing the data points\n",
    "    \n",
    "    features: list of features picked to form the feature matrix\n",
    "    \n",
    "    label: The target feature of the model\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    feature_matrix : A 2D array containing all features for all data points\n",
    "    \n",
    "    label_array : A 1D array containing the class labels for all instances\n",
    "    \"\"\"\n",
    "    df['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    feature_matrix = df[features].as_matrix()\n",
    "    label_array = df[label].as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_feature_matrix(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, weights):\n",
    "    \"\"\"\n",
    "    Predict the probabilitie of each instances as class 1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: The 2D array containing all selected features of all data points\n",
    "    \n",
    "    weights: The learnt coefficients of the linear score function\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    prob: The probility of all instances as class 1\n",
    "    \"\"\"\n",
    "    scores = np.dot(feature_matrix,weights)\n",
    "    prob = 1 / (1+np.exp(-scores))\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: A test of the previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The derivative for single feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    \"\"\"\n",
    "    compute the derivative of the log-likelihood with respect to a single feature\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    errors: A 1D array containing differences between the boolean of the instance as 1 and its probility to be 1\n",
    "    \n",
    "    feature: A 1D array containing values of a single feature for all data points\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The derivative of the log-likelihood, which is the derivative with respect to a single coefficient w_j. \n",
    "    \"\"\"\n",
    "    return np.dot(errors,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log-likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix,sentiment,weights):\n",
    "    \"\"\"\n",
    "    compute the log-likelihood of all features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: A 2D array containing all selected featuers of all instances\n",
    "    \n",
    "    sentiment: A 1D array containing class lables of all instances\n",
    "    \n",
    "    weights: The coefficients of all features\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    log_like : The log likelihood for the current iteration\n",
    "    \"\"\"\n",
    "    indicator = sentiment == 1\n",
    "    scores = np.dot(feature_matrix,weights)\n",
    "    log_like = np.sum((indicator-1)*scores - np.log(1.+np.exp(-scores)))\n",
    "    \n",
    "    return log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the derivative related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.33141161544\n",
      "output of compute_log_likelihood = -5.33141161544\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ -1==+1,1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])),np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll = sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_log_likelihood           =', correct_ll\n",
    "print 'output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_sentiment, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix, sentiment, \n",
    "                        initial_coefficients, step_size, max_iter):\n",
    "    \"\"\"\n",
    "    learn the optimal weights for the logistic regression model using gradiend ascent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix: A 2D array of features for all instances\n",
    "    \n",
    "    sentimnet: A 1D array of true class labels\n",
    "    \n",
    "    initial_coefficients: The initial weights for all features\n",
    "    \n",
    "    step_size: The step_size for gradient ascent\n",
    "    \n",
    "    max_iter: The limit number of iterations\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The final coefficents for all features(a 1D array)\n",
    "    \"\"\"\n",
    "    weights = np.array(initial_coefficients)\n",
    "    \n",
    "    for itr in range(max_iter):\n",
    "        prediction = predict_probability(feature_matrix, weights)\n",
    "        indicator = sentiment == 1\n",
    "        errors = indicator - prediction\n",
    "        \n",
    "        for j in range(len(weights)):\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "            weights[j] += step_size * derivative\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, weights)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)      \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model to learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36775.36728268\n",
      "iteration   1: log likelihood of observed labels = -36764.12455183\n",
      "iteration   2: log likelihood of observed labels = -36752.97527093\n",
      "iteration   3: log likelihood of observed labels = -36741.91590009\n",
      "iteration   4: log likelihood of observed labels = -36730.94305575\n",
      "iteration   5: log likelihood of observed labels = -36720.05350394\n",
      "iteration   6: log likelihood of observed labels = -36709.24415380\n",
      "iteration   7: log likelihood of observed labels = -36698.51205139\n",
      "iteration   8: log likelihood of observed labels = -36687.85437371\n",
      "iteration   9: log likelihood of observed labels = -36677.26842295\n",
      "iteration  10: log likelihood of observed labels = -36666.75162105\n",
      "iteration  11: log likelihood of observed labels = -36656.30150438\n",
      "iteration  12: log likelihood of observed labels = -36645.91571871\n",
      "iteration  13: log likelihood of observed labels = -36635.59201438\n",
      "iteration  14: log likelihood of observed labels = -36625.32824161\n",
      "iteration  15: log likelihood of observed labels = -36615.12234613\n",
      "iteration  20: log likelihood of observed labels = -36564.89529021\n",
      "iteration  30: log likelihood of observed labels = -36467.82955415\n",
      "iteration  40: log likelihood of observed labels = -36374.30229613\n",
      "iteration  50: log likelihood of observed labels = -36283.51326036\n",
      "iteration  60: log likelihood of observed labels = -36194.94645228\n",
      "iteration  70: log likelihood of observed labels = -36108.26474835\n",
      "iteration  80: log likelihood of observed labels = -36023.24377655\n",
      "iteration  90: log likelihood of observed labels = -35939.73043761\n",
      "iteration 100: log likelihood of observed labels = -35857.61685875\n",
      "iteration 200: log likelihood of observed labels = -35101.75207268\n",
      "iteration 300: log likelihood of observed labels = -34444.27949665\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （Own experiment of tuning step_size）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -40801.83940538\n",
      "iteration   1: log likelihood of observed labels = -305491.31527983\n",
      "iteration   2: log likelihood of observed labels = -287437.70722149\n",
      "iteration   3: log likelihood of observed labels = -225046.99200230\n",
      "iteration   4: log likelihood of observed labels = -319964.77159845\n",
      "iteration   5: log likelihood of observed labels = -149401.85327191\n",
      "iteration   6: log likelihood of observed labels = -331743.80178196\n",
      "iteration   7: log likelihood of observed labels = -104425.51723589\n",
      "iteration   8: log likelihood of observed labels = -280117.07484287\n",
      "iteration   9: log likelihood of observed labels = -121174.06258823\n",
      "iteration  10: log likelihood of observed labels = -265335.82234271\n",
      "iteration  11: log likelihood of observed labels = -112545.67693600\n",
      "iteration  12: log likelihood of observed labels = -233343.17991458\n",
      "iteration  13: log likelihood of observed labels = -119707.94841859\n",
      "iteration  14: log likelihood of observed labels = -222766.23644887\n",
      "iteration  15: log likelihood of observed labels = -115143.54942304\n",
      "iteration  20: log likelihood of observed labels = -185033.48622265\n",
      "iteration  30: log likelihood of observed labels = -153842.44421199\n",
      "iteration  40: log likelihood of observed labels = -136095.16019304\n",
      "iteration  50: log likelihood of observed labels = -125986.93824314\n",
      "iteration  60: log likelihood of observed labels = -119651.62353786\n",
      "iteration  70: log likelihood of observed labels = -115263.88538555\n",
      "iteration  80: log likelihood of observed labels = -112039.61369422\n",
      "iteration  90: log likelihood of observed labels = -109466.78238006\n",
      "iteration 100: log likelihood of observed labels = -107353.25480928\n",
      "iteration 200: log likelihood of observed labels = -97132.32890109\n",
      "iteration 300: log likelihood of observed labels = -93416.72522645\n"
     ]
    }
   ],
   "source": [
    "coefficients3 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-4, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -35892.79887963\n",
      "iteration   1: log likelihood of observed labels = -35138.30167197\n",
      "iteration   2: log likelihood of observed labels = -34498.09230738\n",
      "iteration   3: log likelihood of observed labels = -33926.93024038\n",
      "iteration   4: log likelihood of observed labels = -33426.47718771\n",
      "iteration   5: log likelihood of observed labels = -32955.63297414\n",
      "iteration   6: log likelihood of observed labels = -32534.54152791\n",
      "iteration   7: log likelihood of observed labels = -32130.66610131\n",
      "iteration   8: log likelihood of observed labels = -31767.29274598\n",
      "iteration   9: log likelihood of observed labels = -31423.30318664\n",
      "iteration  10: log likelihood of observed labels = -31112.92753696\n",
      "iteration  11: log likelihood of observed labels = -30824.43165046\n",
      "iteration  12: log likelihood of observed labels = -30561.97850986\n",
      "iteration  13: log likelihood of observed labels = -30319.45682083\n",
      "iteration  14: log likelihood of observed labels = -30096.06658322\n",
      "iteration  15: log likelihood of observed labels = -29888.47274504\n",
      "iteration  20: log likelihood of observed labels = -29028.72336745\n",
      "iteration  30: log likelihood of observed labels = -27846.02702031\n",
      "iteration  40: log likelihood of observed labels = -27056.55874931\n",
      "iteration  50: log likelihood of observed labels = -26487.09158446\n",
      "iteration  60: log likelihood of observed labels = -26054.67501495\n",
      "iteration  70: log likelihood of observed labels = -25713.96113014\n",
      "iteration  80: log likelihood of observed labels = -25437.87953879\n",
      "iteration  90: log likelihood of observed labels = -25209.20631454\n",
      "iteration 100: log likelihood of observed labels = -25016.43205769\n",
      "iteration 200: log likelihood of observed labels = -24015.82721239\n",
      "iteration 300: log likelihood of observed labels = -23630.89726180\n"
     ]
    }
   ],
   "source": [
    "## own experiment on step_size\n",
    "coefficients2 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-5, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -35741.41177794\n",
      "iteration   1: log likelihood of observed labels = -35037.43761085\n",
      "iteration   2: log likelihood of observed labels = -34798.91220270\n",
      "iteration   3: log likelihood of observed labels = -34811.33611600\n",
      "iteration   4: log likelihood of observed labels = -35378.06925980\n",
      "iteration   5: log likelihood of observed labels = -34868.59096597\n",
      "iteration   6: log likelihood of observed labels = -35211.95945269\n",
      "iteration   7: log likelihood of observed labels = -33899.30545839\n",
      "iteration   8: log likelihood of observed labels = -33970.79361608\n",
      "iteration   9: log likelihood of observed labels = -32723.41084611\n",
      "iteration  10: log likelihood of observed labels = -32644.16029290\n",
      "iteration  11: log likelihood of observed labels = -31661.01385026\n",
      "iteration  12: log likelihood of observed labels = -31485.91194390\n",
      "iteration  13: log likelihood of observed labels = -30745.57951567\n",
      "iteration  14: log likelihood of observed labels = -30517.96479126\n",
      "iteration  15: log likelihood of observed labels = -29966.99849016\n",
      "iteration  20: log likelihood of observed labels = -28547.64513660\n",
      "iteration  30: log likelihood of observed labels = -27134.29051742\n",
      "iteration  40: log likelihood of observed labels = -26423.04870668\n",
      "iteration  50: log likelihood of observed labels = -25918.19863014\n",
      "iteration  60: log likelihood of observed labels = -25537.20170389\n",
      "iteration  70: log likelihood of observed labels = -25238.55987475\n",
      "iteration  80: log likelihood of observed labels = -24997.67238775\n",
      "iteration  90: log likelihood of observed labels = -24798.99112614\n",
      "iteration 100: log likelihood of observed labels = -24632.18532513\n",
      "iteration 200: log likelihood of observed labels = -23783.79786620\n",
      "iteration 300: log likelihood of observed labels = -23474.46304347\n"
     ]
    }
   ],
   "source": [
    "coefficients4 = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1.25e-5, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['predic_prob1'] = predict_probability(feature_matrix,coefficients)\n",
    "products['predic_prob2'] = predict_probability(feature_matrix,coefficients2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict sentiment using the learnt coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix,coefficients)\n",
    "scores2 = np.dot(feature_matrix,coefficients2)\n",
    "scores4 = np.dot(feature_matrix,coefficients4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['predic_scores1'] = scores\n",
    "products['predic_scores2'] = scores2\n",
    "products['predic_scores4'] = scores4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['predic_sentiment1'] = products['predic_scores1'].apply(lambda s: 1 if s>0 else -1)\n",
    "products['predic_sentiment2'] = products['predic_scores2'].apply(lambda s: 1 if s>0 else -1)\n",
    "products['predic_sentiment4'] = products['predic_scores4'].apply(lambda s: 1 if s>0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24423, 26068)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of positive_predicted instances\n",
    "(products['predic_sentiment1'] == 1).sum(),(products['predic_sentiment2'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74, 0.7993)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of coefficients and coefficients2\n",
    "round((products['predic_sentiment1'] == products['sentiment']).sum()*1./products.shape[0],2),round((products['predic_sentiment2'] == products['sentiment']).sum()*1./products.shape[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of coefficients4 which is believed to be opitimum regarding the step_size\n",
    "round((products['predic_sentiment4'] == products['sentiment']).sum()*1./products.shape[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients)[1:]\n",
    "word_coefficient_paris = [(word,coef) for word,coef in zip(important_words,coefficients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_coef_dict = {a:b for a,b in zip(important_words,coefficients)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03583028769555744"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coef_dict['work']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ten most positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 0.11485512972899151),\n",
       " ('great', 0.070255174595001635),\n",
       " ('easy', 0.06728827346724775),\n",
       " ('little', 0.048671064877459043),\n",
       " ('loves', 0.043117605892266361),\n",
       " ('perfect', 0.043094103127603575),\n",
       " ('old', 0.039751364733730123),\n",
       " ('well', 0.034230940747470302),\n",
       " ('able', 0.028612995130438346),\n",
       " ('daughter', 0.025786498659130356)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_coefficient_paris,key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ten most negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', -0.055627299480496724),\n",
       " ('return', -0.053075214662185677),\n",
       " ('product', -0.042461104690891809),\n",
       " ('money', -0.037007585179380666),\n",
       " ('work', -0.03583028769555744),\n",
       " ('one', -0.032410014190202972),\n",
       " ('disappointed', -0.028521910126023561),\n",
       " ('get', -0.027573075630982241),\n",
       " ('us', -0.027328738685513963),\n",
       " ('even', -0.026471612072450475)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_coefficient_paris,key=lambda x: x[1])[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
